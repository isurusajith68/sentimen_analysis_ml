{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../artifacts/sentiment_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnancy test  android apps beaut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>finally a transparant silicon case  thanks to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>we love this would you go talk makememories un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>im wired i know im george i was made that way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>what amazing service apple wont even talk to m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  fingerprint pregnancy test  android apps beaut...\n",
       "1   2      0  finally a transparant silicon case  thanks to ...\n",
       "2   3      0  we love this would you go talk makememories un...\n",
       "3   4      0  im wired i know im george i was made that way ...\n",
       "4   5      1  what amazing service apple wont even talk to m..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data size\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#duplicate data\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data null values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##text preprocessing\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert uppercase to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet'] = data['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "data['tweet'].head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fingerprint pregnancy test android apps beauti...\n",
       "1    finally a transparant silicon case thanks to m...\n",
       "2    we love this would you go talk makememories un...\n",
       "3    im wired i know im george i was made that way ...\n",
       "4    what amazing service apple wont even talk to m...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet'] = data['tweet'].apply(lambda x: \" \".join(re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE) for x in x.split()))\n",
    "data['tweet'].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuataions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7915    live out loud lol liveoutloud selfie smile son...\n",
       "7916    we would like to wish you an amazing day make ...\n",
       "7917    helping my lovely  year old neighbor with her ...\n",
       "7918    finally got my smart pocket wifi stay connecte...\n",
       "7919    apple barcelona apple store bcn barcelona trav...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "data['tweet'] = data['tweet'].apply(remove_punctuation)\n",
    "\n",
    "data['tweet'].tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7915    live out loud lol liveoutloud selfie smile son...\n",
       "7916    we would like to wish you an amazing day make ...\n",
       "7917    helping my lovely  year old neighbor with her ...\n",
       "7918    finally got my smart pocket wifi stay connecte...\n",
       "7919    apple barcelona apple store bcn barcelona trav...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove numbers\n",
    "data['tweet'] = data['tweet'].str.replace('\\d+', '', regex=True)\n",
    "data['tweet'].tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove stopwords by nltk\n",
    "stopwords ex: is , are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "                                              0.0/1.5 MB 435.7 kB/s eta 0:00:04\n",
      "                                              0.0/1.5 MB 435.7 kB/s eta 0:00:04\n",
      "                                              0.0/1.5 MB 435.7 kB/s eta 0:00:04\n",
      "     -                                        0.0/1.5 MB 140.9 kB/s eta 0:00:11\n",
      "     --                                       0.1/1.5 MB 270.5 kB/s eta 0:00:06\n",
      "     --                                       0.1/1.5 MB 275.8 kB/s eta 0:00:06\n",
      "     --                                       0.1/1.5 MB 275.8 kB/s eta 0:00:06\n",
      "     --                                       0.1/1.5 MB 275.8 kB/s eta 0:00:06\n",
      "     --                                       0.1/1.5 MB 234.3 kB/s eta 0:00:06\n",
      "     ----                                     0.2/1.5 MB 327.7 kB/s eta 0:00:05\n",
      "     -----                                    0.2/1.5 MB 405.0 kB/s eta 0:00:04\n",
      "     -----                                    0.2/1.5 MB 405.0 kB/s eta 0:00:04\n",
      "     -----                                    0.2/1.5 MB 405.0 kB/s eta 0:00:04\n",
      "     --------                                 0.3/1.5 MB 432.3 kB/s eta 0:00:03\n",
      "     ----------                               0.4/1.5 MB 527.7 kB/s eta 0:00:03\n",
      "     -------------                            0.5/1.5 MB 629.1 kB/s eta 0:00:02\n",
      "     -------------                            0.5/1.5 MB 629.1 kB/s eta 0:00:02\n",
      "     -------------                            0.5/1.5 MB 596.0 kB/s eta 0:00:02\n",
      "     -----------------                        0.7/1.5 MB 699.7 kB/s eta 0:00:02\n",
      "     ---------------------                    0.8/1.5 MB 814.5 kB/s eta 0:00:01\n",
      "     -------------------------                1.0/1.5 MB 938.2 kB/s eta 0:00:01\n",
      "     ---------------------------              1.0/1.5 MB 954.6 kB/s eta 0:00:01\n",
      "     -----------------------------            1.1/1.5 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------        1.3/1.5 MB 1.1 MB/s eta 0:00:01\n",
      "     --------------------------------------   1.4/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "                                              0.0/96.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 96.6/96.6 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "                                              0.0/298.0 kB ? eta -:--:--\n",
      "     ------------------------               194.6/298.0 kB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 298.0/298.0 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2023.6.3-cp310-cp310-win_amd64.whl (268 kB)\n",
      "                                              0.0/268.0 kB ? eta -:--:--\n",
      "     ------------------------               174.1/268.0 kB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 268.0/268.0 kB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in d:\\maching lerning\\sentimen_analysis_ml\\env2\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in d:\\maching lerning\\sentimen_analysis_ml\\env2\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.3 joblib-1.2.0 nltk-3.8.1 regex-2023.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to ../static/model/...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords', download_dir='../static/model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/corpora/stopwords/english', 'r') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet'] = data['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       fingerprint pregnancy test android apps beauti...\n",
       "1       finally transparant silicon case thanks uncle ...\n",
       "2       love would go talk makememories unplug relax i...\n",
       "3       im wired know im george made way iphone cute d...\n",
       "4       amazing service apple wont even talk question ...\n",
       "                              ...                        \n",
       "7915    live loud lol liveoutloud selfie smile sony mu...\n",
       "7916    would like wish amazing day make every minute ...\n",
       "7917    helping lovely year old neighbor ipad morning ...\n",
       "7918    finally got smart pocket wifi stay connected a...\n",
       "7919    apple barcelona apple store bcn barcelona trav...\n",
       "Name: tweet, Length: 7920, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet'] = data['tweet'].apply(lambda x: \" \".join(ps.stem(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnanc test android app beauti c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>final transpar silicon case thank uncl yay son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>love would go talk makememori unplug relax iph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>im wire know im georg made way iphon cute dave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>amaz servic appl wont even talk question unles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>7916</td>\n",
       "      <td>0</td>\n",
       "      <td>live loud lol liveoutloud selfi smile soni mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>7917</td>\n",
       "      <td>0</td>\n",
       "      <td>would like wish amaz day make everi minut coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>help love year old neighbor ipad morn made rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>7919</td>\n",
       "      <td>0</td>\n",
       "      <td>final got smart pocket wifi stay connect anyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>appl barcelona appl store bcn barcelona travel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet\n",
       "0        1      0  fingerprint pregnanc test android app beauti c...\n",
       "1        2      0  final transpar silicon case thank uncl yay son...\n",
       "2        3      0  love would go talk makememori unplug relax iph...\n",
       "3        4      0  im wire know im georg made way iphon cute dave...\n",
       "4        5      1  amaz servic appl wont even talk question unles...\n",
       "...    ...    ...                                                ...\n",
       "7915  7916      0  live loud lol liveoutloud selfi smile soni mus...\n",
       "7916  7917      0  would like wish amaz day make everi minut coun...\n",
       "7917  7918      0  help love year old neighbor ipad morn made rea...\n",
       "7918  7919      0  final got smart pocket wifi stay connect anyti...\n",
       "7919  7920      0  appl barcelona appl store bcn barcelona travel...\n",
       "\n",
       "[7920 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
